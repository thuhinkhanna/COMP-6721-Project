{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thuhinkhanna/COMP-6721-Project/blob/main/AI_Project_Fashion_Products_Images_Small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qtKO_WZCtRSB"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d paramaggarwal/fashion-product-images-small\n",
        "!unzip fashion-product-images-small.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqbSZaxbuRt1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/myntradataset/styles.csv', error_bad_lines=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvx4OLnSvX-G"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDABt-xUJe_H"
      },
      "source": [
        "The dataset contains 44424 rows and 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG7-akIQvbE5"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uARBF-V5vfz2"
      },
      "outputs": [],
      "source": [
        "df['masterCategory'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdGDKx3VHYOt"
      },
      "outputs": [],
      "source": [
        "category_counts = df['masterCategory'].value_counts()\n",
        "print(category_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjbOTsldLh6b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "category_counts.plot(kind='bar', color='skyblue', figsize=(10, 6))\n",
        "plt.xlabel('Categories')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Count of Items per Category')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability if needed\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wY1hfRXMhB6"
      },
      "source": [
        "From the graph it can be seen that the three master categories Free items, Sporting Goods and Home datas are negligible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIDKzMsoMzFk"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sd16QfMod0HB"
      },
      "outputs": [],
      "source": [
        "!ls /content/images | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3HJ85b8M4h9"
      },
      "source": [
        "The number of images are different from the number of Ids present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVb1Bj_jThDp"
      },
      "outputs": [],
      "source": [
        "import os,numpy as np\n",
        "image_folder = 'myntradataset/images'\n",
        "image_files = os.listdir(image_folder)\n",
        "dataset_ids = df['id'].astype(str) + '.jpg'\n",
        "dataset_ids_set = set(dataset_ids)\n",
        "image_files_set = set(image_files)\n",
        "#Missing images are calculated.\n",
        "missing_images = dataset_ids_set - image_files_set\n",
        "#Extra images with no corresponding ids are calculated.\n",
        "extra_images = image_files_set - dataset_ids_set\n",
        "print(missing_images)\n",
        "print(extra_images)\n",
        "\n",
        "print(df['id'].dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx_Jm9zWeTMD"
      },
      "outputs": [],
      "source": [
        "\n",
        "missing_imgs = list(missing_images)\n",
        "missing=[]\n",
        "for i in missing_imgs:\n",
        "  missing.append(np.int64(i[:-4]))\n",
        "df=df[~df['id'].isin(missing)]\n",
        "df = df.loc[~df['id'].isin(missing), :]\n",
        "print(df.shape)\n",
        "# New column named 'image' is created with no id column.\n",
        "df['image'] = df.apply(lambda row: str(row['id']) + \".jpg\", axis=1)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtACqR0jTaV-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVWg_EGnC7Wi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "base_dir = '/content/Images_'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(base_dir):\n",
        "    os.makedirs(base_dir)\n",
        "\n",
        "# Create subfolders(List of classes).\n",
        "subfolders = ['Apparel', 'Accessories', 'Footwear', 'Personal Care']\n",
        "for folder in subfolders:\n",
        "    folder_path = os.path.join(base_dir, folder)\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gReTso0AFegV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "# Function to resize an image\n",
        "def resize_image(image_path, output_size):\n",
        "    img = Image.open(image_path)\n",
        "    img_resized = img.resize(output_size, Image.ANTIALIAS)\n",
        "    return img_resized\n",
        "\n",
        "category_mapping = {\n",
        "    'Accessories': '/content/Images_/Accessories',\n",
        "    'Apparel': '/content/Images_/Apparel',\n",
        "    'Footwear': '/content/Images_/Footwear',\n",
        "    'Personal Care': '/content/Images_/Personal Care',\n",
        "}\n",
        "\n",
        "# Set to keep track of moved items\n",
        "moved_items = set()\n",
        "\n",
        "# Output size for resized images (e.g., (width, height))\n",
        "output_size = (224, 224)  # Adjust as needed\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    item_id = row['id']\n",
        "    master_category = row['masterCategory']\n",
        "    item = str(item_id) + '.jpg'\n",
        "\n",
        "    if master_category in category_mapping:\n",
        "        source_path = '/content/myntradataset/images/' + item\n",
        "        destination_path = category_mapping[master_category]\n",
        "\n",
        "        # Check if the item has already been moved\n",
        "        if item not in moved_items:\n",
        "            # Check if destination file already exists\n",
        "            if not os.path.exists(os.path.join(destination_path, item)):\n",
        "                # Resize image\n",
        "                resized_image = resize_image(source_path, output_size)\n",
        "                # Save resized image to destination\n",
        "                resized_image.save(os.path.join(destination_path, item))\n",
        "                # Add item to set of moved items\n",
        "                moved_items.add(item)\n",
        "            else:\n",
        "                print(f\"Destination file {item} already exists in {destination_path}. Skipping...\")\n",
        "        else:\n",
        "            print(f\"Item {item} already moved. Skipping...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6p7RVH0PhpS"
      },
      "outputs": [],
      "source": [
        "#Checking if the images have been resized to 224*224 to train the model.\n",
        "from PIL import Image\n",
        "img = Image.open(\"/content/Images_/Accessories/10734.jpg\")\n",
        "\n",
        "# Get the dimensions of the image\n",
        "width, height = img.size\n",
        "\n",
        "# Print the dimensions\n",
        "print(\"Width:\", width)\n",
        "print(\"Height:\", height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwVQdFteF5L9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as td\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go_aJqF2OQ61"
      },
      "outputs": [],
      "source": [
        "#Function to split data into train, test and validation data and perform normalization.\n",
        "def load_data(path, test_split, val_split, batch_size):\n",
        "    transform_dict = {\n",
        "    'src': transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                          std=[0.5, 0.5, 0.5]),\n",
        "     ])}\n",
        "\n",
        "    data = datasets.ImageFolder(root=path, transform=transform_dict['src'])\n",
        "    dataset_size = len(data)\n",
        "    test_size = int(test_split * dataset_size)\n",
        "    val_size = int(val_split * dataset_size)\n",
        "    train_size = dataset_size - (test_size + val_size)\n",
        "\n",
        "    train_dataset, test_dataset, val_dataset = td.random_split(data,\n",
        "                                               [train_size, test_size, val_size])\n",
        "\n",
        "    data_loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=0)\n",
        "    data_loader_test  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=0)\n",
        "    data_loader_val   = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=0)\n",
        "    return data_loader_train, data_loader_test, data_loader_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okdAju4fjz1l"
      },
      "outputs": [],
      "source": [
        "path='/content/Images_'\n",
        "train_loader, test_loader, val_loader = load_data(path, 0.3, 0.1, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ougnRGM4Q6Te"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhxqjjc1jvKT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "# Loading the ResNet-18 model\n",
        "model = models.resnet18(pretrained=False)\n",
        "\n",
        "# Modify the last layer for 4 classes\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 4)\n",
        "\n",
        "# Define optimizer and criterion\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Moving the model to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"Device: {}\".format(device))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jaw5ruHsH2fa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        inputs, labels = inputs.cuda().to(device), labels.cuda().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(train_loader)}], Train Loss: {loss.item():.4f}')\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy = correct_train / total_train\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
        "\n",
        "            inputs, labels = inputs.cuda().to(device), labels.cuda().to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "            total_val += labels.size(0)\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(val_loader)}], Val Loss: {loss.item():.4f}')\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = correct_val / total_val\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "print('Training complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFUztq-HJI_R"
      },
      "outputs": [],
      "source": [
        "#Evaluation to check the test accuracy.\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, (correct / total) * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCCFHAQSMipP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, 11), train_losses, label='Training Loss')\n",
        "plt.plot(range(1, 11), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting training and validation accuracy\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtcK5zpeGz6r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "model = models.vgg16(pretrained=False)\n",
        "num_features = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Sequential(\n",
        "    nn.Linear(num_features, 256),\n",
        "    nn.ReLU(),\n",
        ")\n",
        "for param in model.classifier[6].parameters():\n",
        "    param.requires_grad = True\n",
        "    # Define optimizer and criterion\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "path='/content/Images_'\n",
        "train_loader, test_loader, val_loader = load_data(path, 0.3, 0.1, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogtxlXQEmX8p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        inputs, labels = inputs.cuda().to(device), labels.cuda().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(train_loader)}], Train Loss: {loss.item():.4f}')\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy = correct_train / total_train\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
        "\n",
        "            inputs, labels = inputs.cuda().to(device), labels.cuda().to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "            total_val += labels.size(0)\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(val_loader)}], Val Loss: {loss.item():.4f}')\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = correct_val / total_val\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "print('Training complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqFxhLzPNMB8"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, (correct / total) * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WfPcBY4HL60"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1,  num_epochs+1), train_losses, label='Training Loss')\n",
        "plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting training and validation accuracy\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}